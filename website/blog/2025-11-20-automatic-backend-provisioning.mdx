---
slug: automatic-backend-provisioning
title: "Automatic Backend Provisioning: Simplify Your Terraform State Management"
authors: [osterman]
tags: [feature, terraform, backend, s3, automation]
---

We're excited to introduce **automatic backend provisioning** in Atmos, a feature that eliminates the chicken-and-egg problem of managing Terraform state backends. No more manual S3 bucket creation, no more separate Terraform modules just to bootstrap your state storage—Atmos now handles it automatically.

<!--truncate-->

## The Problem: State Backend Bootstrapping

Every Terraform project faces the same bootstrapping challenge: before you can manage infrastructure, you need somewhere to store your state. The typical workflow looks like this:

1. Manually create an S3 bucket via AWS Console or CLI
2. Configure bucket versioning, encryption, and public access blocking
3. Set up DynamoDB table for state locking (optional with Terraform 1.10+)
4. Finally, start using Terraform

This creates friction for new projects, complicates CI/CD pipelines, and introduces manual steps that conflict with infrastructure-as-code principles.

## The Solution: Automatic Provisioning

Atmos now provisions backends automatically when needed. Just enable it in your stack configuration:

```yaml
components:
  terraform:
    vpc:
      backend:
        bucket: my-terraform-state
        key: vpc/terraform.tfstate
        region: us-east-1
        backend_type: s3

      provision:
        backend:
          enabled: true  # That's it!
```

When you run `atmos terraform plan vpc -s dev`, Atmos:

1. **Checks** if the backend exists
2. **Provisions** it if needed (with secure defaults)
3. **Initializes** Terraform
4. **Continues** with your command

All automatically. No manual intervention required.

## Secure by Default

The S3 backend provisioner applies hardcoded security best practices:

- ✅ **Versioning enabled** - Protect against accidental deletions
- ✅ **AES-256 encryption** - AWS-managed keys, always enabled
- ✅ **Public access blocked** - All four block settings enabled
- ✅ **Native S3 locking** - Terraform 1.10+ support (no DynamoDB needed)
- ✅ **Resource tags** - Automatic tagging for cost allocation

These settings aren't configurable—they're opinionated defaults that follow AWS security best practices.

## Perfect for Development, Ready for Production

The automatic provisioning feature is designed for **development and testing workflows**, where you need backends quickly without manual setup. For production environments, we recommend:

1. Start with automatic provisioning during development
2. Use `atmos provision backend` to create the backend
3. Import the provisioned backend into Terraform for production management:

```hcl
import {
  to = aws_s3_bucket.terraform_state
  id = "my-terraform-state"
}

resource "aws_s3_bucket" "terraform_state" {
  bucket = "my-terraform-state"
}

# Add your production-specific settings
resource "aws_s3_bucket_lifecycle_configuration" "terraform_state" {
  # ... lifecycle policies
}

resource "aws_s3_bucket_replication_configuration" "terraform_state" {
  # ... cross-region replication
}
```

This provides a **migration path** from development to production while maintaining infrastructure-as-code principles.

## Cross-Account Support

Provisioners integrate with Atmos AuthManager for cross-account operations:

```yaml
components:
  terraform:
    vpc:
      backend:
        bucket: my-terraform-state
        region: us-east-1
        assume_role:
          role_arn: arn:aws:iam::999999999999:role/TerraformStateAdmin

      provision:
        backend:
          enabled: true
```

The provisioner automatically assumes the role to create the bucket in the target account.

## CLI Command

For manual provisioning or CI/CD pipelines, use the new `atmos provision` command:

```bash
# Provision backend explicitly
atmos provision backend vpc --stack dev

# Automatic in CI/CD
atmos provision backend vpc --stack dev
atmos provision backend eks --stack dev
atmos terraform apply vpc --stack dev  # Only runs if provisioning succeeded
```

Provisioning failures return non-zero exit codes, ensuring CI/CD pipelines fail fast.

## Extensible Architecture

The provisioner system is built on a **self-registering architecture** that makes it easy to add support for additional backend types and provisioner types in the future

Backend provisioners register themselves and declare when they should run via hook events:

```go
// Register S3 backend provisioner
provisioner.RegisterProvisioner(provisioner.Provisioner{
    Type:      "backend",
    HookEvent: "before.terraform.init",
    Func:      ProvisionS3Backend,
})
```

## Getting Started

Enable automatic backend provisioning in your stack configuration:

```yaml
# stacks/dev.yaml
components:
  terraform:
    vpc:
      backend:
        bucket: acme-terraform-state-dev
        key: vpc/terraform.tfstate
        region: us-east-1
        backend_type: s3

      provision:
        backend:
          enabled: true
```

Then run your Terraform commands as usual:

```bash
atmos terraform plan vpc -s dev
# Backend provisioned automatically if needed
```

For more information:
- [CLI Documentation](/cli/commands/provision/backend)
- [Configuration Schema](/core-concepts/stacks/configuration)
- [Migration Guide](/core-concepts/backends/migration-to-production)

## Community Feedback

We'd love to hear how you're using automatic backend provisioning! Share your experience in [GitHub Discussions](https://github.com/cloudposse/atmos/discussions) or report any issues in our [issue tracker](https://github.com/cloudposse/atmos/issues).

---

**Try it today** and simplify your Terraform state management workflow!

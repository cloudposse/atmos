---
slug: introducing-atmos-ai
title: "Introducing Atmos AI: Your Infrastructure-Aware AI Assistant"
authors: [atmos]
tags: [feature, ai, productivity, infrastructure]
---

We're excited to introduce **Atmos AI**, an intelligent assistant built directly into Atmos CLI that understands your infrastructure-as-code like no other AI assistant can.

Unlike general-purpose AI coding assistants, Atmos AI has deep, native understanding of Atmos stacks, components, inheritance patterns, and infrastructure workflows. It's not just an AI that knows about codeâ€”it's an AI that truly understands *your infrastructure*.

With support for 7 AI providers (including local/offline Ollama), persistent sessions with full conversation memory, tool execution with granular permissions, specialized agents for specific tasks, and seamless IDE integration via MCPâ€”Atmos AI brings the productivity patterns of industry-leading AI systems to infrastructure management.

<!--truncate-->

## The Problem

Infrastructure-as-code management is complex. Engineers spend hours:

- **Searching documentation** for the right Atmos command or configuration pattern
- **Debugging YAML configurations** with cryptic validation errors
- **Understanding stack inheritance** and component relationships across dozens of files
- **Reviewing configurations** for security issues or best practices
- **Onboarding team members** who need to learn organizational conventions

Even experienced teams lose productivity to context switching, documentation hunting, and configuration debugging. The problem isn't lack of toolsâ€”it's the **cognitive overhead** of managing complex infrastructure.

## The Solution: Atmos AI

Atmos AI solves this through **infrastructure-aware intelligence** that understands your Atmos configurations, not just generic code. It's like having an expert Atmos engineer available 24/7, ready to analyze your stacks, validate configurations, answer questions, and help with best practices.

### What Makes Atmos AI Different?

**Deep Atmos Understanding:**
- Knows Atmos stack structure and inheritance patterns
- Understands component relationships and dependencies
- Can analyze your actual infrastructure configurations
- Provides context-aware recommendations

**Full Conversation Memory:**
- Remembers entire chat history within sessions
- Understands follow-up questions and references
- Resume conversations days or weeks later with full context
- Build on previous discussions naturally

**Tool Execution:**
- Can analyze your infrastructure automatically
- Execute read-only operations (`describe`, `list`, `validate`)
- Real-time YAML/Terraform validation via LSP integration
- Granular permission system for safety

**Multi-Provider Support:**
- 7 AI providers: Claude, GPT, Gemini, Grok, Ollama, AWS Bedrock, Azure OpenAI
- Switch providers mid-conversation (Ctrl+P)
- Each session remembers its provider
- Local/offline option with Ollama

**Persistent Sessions:**
- SQLite-backed conversation storage
- Named sessions for organization
- Auto-compact for extended conversations
- Cross-platform session management

## Key Features

### 1. Infrastructure-Aware Intelligence

Atmos AI isn't just a chatbotâ€”it has **native tools** to inspect your infrastructure:

```bash
You: What VPC CIDR does production use?

AI: Let me check your configuration...
    [Executes: atmos describe component vpc -s prod-use1-network]

    Your production VPC (prod-use1-network) uses CIDR 10.2.0.0/16.

    I can see you're also using:
    - Public subnets: 10.2.0.0/24, 10.2.1.0/24, 10.2.2.0/24
    - Private subnets: 10.2.10.0/24, 10.2.11.0/24, 10.2.12.0/24
    - NAT Gateway: Enabled in all AZs

    Would you like me to analyze the security groups as well?
```

**Available Tools:**
- `atmos_describe_component` - Analyze component configurations
- `atmos_describe_stacks` - Review all stacks
- `atmos_list_stacks` - List available stacks
- `atmos_list_components` - List components
- `atmos_validate_stacks` - Validate configurations
- `validate_file_lsp` - Real-time YAML/Terraform validation
- File operations (read/write/search)
- Web search for documentation

### 2. Real-Time Validation with LSP

Atmos AI integrates with Language Server Protocol (LSP) to provide **IDE-quality validation** directly in the chat:

```bash
You: Validate stacks/prod/vpc.yaml

AI: [Uses LSP to validate file]

    Found 2 issues in /project/stacks/prod/vpc.yaml:

    ERRORS (1):
    â€¢ Line 15, Col 5: Unknown property 'vpc_ciddr'
      Did you mean 'vpc_cidr'?

    WARNINGS (1):
    â€¢ Line 23, Col 3: Property 'availability_zones' is deprecated
      Use 'azs' instead

    Would you like me to fix these issues for you?
```

**Supported Languages:**
- YAML (stack files)
- Terraform (components)
- HCL (configurations)

### 3. Persistent Sessions with Full Memory

Unlike basic chatbots that forget context, Atmos AI **remembers everything** within a session:

```bash
# Day 1: Start architecture discussion
atmos ai chat --session vpc-migration
> "Let's plan migrating from 10.0.0.0/16 to 10.1.0.0/16"
[Detailed discussion about migration approach...]

# Day 2: Resume with full context
atmos ai chat --session vpc-migration
> "Show me the plan we discussed yesterday"
# âœ… AI has complete context from Day 1

# Week later: Reference earlier decisions
atmos ai chat --session vpc-migration
> "Why did we choose /16 instead of /24 again?"
# âœ… AI can answer based on original discussion
```

**Session Features:**
- SQLite storage for reliability
- Named sessions for organization
- Provider-aware (remembers which AI you used)
- Auto-compact for extended conversations
- Cross-platform session management
- Visual session picker in TUI (Ctrl+L)

### 4. Specialized AI Agents

Different tasks need different expertise. Atmos AI provides **5 built-in specialized agents**:

**1. General (Default)** - Everyday infrastructure questions
- All-purpose assistant
- Full tool access
- Best for learning and exploration

**2. Stack Analyzer** - Architecture analysis
- Analyzes stack configurations and dependencies
- Tools: `describe_*`, `list_*`, `read_stack_file`
- Use case: Architecture reviews, dependency analysis

**3. Component Refactor** - Code improvements
- Refactors Terraform/Helmfile components
- Tools: `read_*`, `write_*`, `search_files`
- Use case: Modernization, code improvements

**4. Security Auditor** - Security reviews
- Security analysis of infrastructure
- Tools: `describe_*`, `read_*`, `validate_*`
- Use case: Security audits, compliance checks

**5. Config Validator** - Configuration troubleshooting
- Validates Atmos configurations
- Tools: `validate_*`, `read_stack_file`, `validate_file_lsp`
- Use case: Debugging config issues

**Switch agents with Ctrl+A** during conversations!

### 5. Multi-Provider Support

Choose the right AI for your needs:

| Provider | Best For | Privacy |
|----------|----------|---------|
| **Anthropic (Claude)** | Complex reasoning, analysis | Cloud |
| **OpenAI (GPT)** | Code generation, refactoring | Cloud |
| **Google (Gemini)** | Large context windows | Cloud |
| **xAI (Grok)** | Real-time knowledge | Cloud |
| **Ollama (Local)** | **Complete privacy, offline** | **100% Local** |
| **AWS Bedrock** | Enterprise, AWS-native | AWS |
| **Azure OpenAI** | Enterprise, Azure-native | Azure |

**Privacy-First Option:**

[Ollama](/ai/providers#ollama) runs AI models **entirely on your machine**:
- **Zero API costs** - No per-token charges
- **Complete privacy** - Data never leaves your computer
- **Offline capable** - No internet required
- **No rate limits** - Query as much as hardware allows
- **Compliance ready** - HIPAA, GDPR, air-gapped environments

Requires 8GB+ RAM (64GB+ recommended for large models).

**Enterprise Options:**

AWS Bedrock and Azure OpenAI provide:
- Data residency controls (data stays in your cloud)
- Enterprise SLAs and compliance certifications
- VPC/VNet isolation
- Audit logging and cost allocation
- IAM/Azure AD integration

### 6. Project Memory (ATMOS.md)

The AI can remember **project-specific context** across all sessions via `ATMOS.md`:

```markdown
# Atmos Project Memory

## Project Context
**Organization:** acme-corp
**Environments:** dev, staging, prod
**Stack Naming:** {org}-{env}-{region}-{stage}

## Common Commands
### Deploy VPC
```bash
atmos terraform plan vpc -s acme-prod-use1-network
atmos terraform apply vpc -s acme-prod-use1-network
```

## Stack Patterns
### Network Stack Structure
All network stacks inherit from:
- catalog/stacks/network/baseline
- catalog/stacks/network/security-groups

### CIDR Blocks
- dev: 10.0.0.0/16
- staging: 10.1.0.0/16
- prod: 10.2.0.0/16
```

This memory file:
- âœ… Shared with AI automatically
- âœ… Human-readable Markdown
- âœ… Version-controlled with your repo
- âœ… Reduces repetitive context loading
- âœ… Customizable sections

### 7. Model Context Protocol (MCP) Integration

Use Atmos tools from **any MCP-compatible client**:

**Claude Desktop Integration:**

```json
{
  "mcpServers": {
    "atmos": {
      "command": "atmos",
      "args": ["mcp-server"]
    }
  }
}
```

Now Claude Desktop can:
- Describe your Atmos components
- List and validate stacks
- Read configuration files
- Provide infrastructure analysis

**Also works with:**
- VSCode/Cursor
- Custom MCP clients
- Remote environments (HTTP transport)

Learn more: [MCP Server documentation](/ai/mcp-server)

### 8. Permission System

**Three-tier security model** protects your infrastructure:

**1. Allowed Tools** - Execute without prompting
```yaml
allowed_tools:
  - atmos_describe_*    # Read-only analysis
  - atmos_list_*        # Safe queries
  - file_read           # Read files
```

**2. Restricted Tools** - Require confirmation
```yaml
restricted_tools:
  - file_write              # File modifications
  - atmos_terraform_plan    # Planning operations
```

**3. Blocked Tools** - Never execute
```yaml
blocked_tools:
  - atmos_terraform_apply    # Infrastructure changes
  - atmos_terraform_destroy  # Destructive operations
```

**Audit Logging:**
```yaml
tools:
  audit:
    enabled: true
    path: .atmos/ai-audit.log
    retention_days: 90
```

Every tool execution logged with timestamp, user, and context.

### 9. Non-Interactive Execution & CI/CD Integration

**NEW:** Atmos AI now supports non-interactive execution for automation, scripting, and CI/CD pipelines.

Execute AI prompts programmatically with structured output:

```bash
# Simple execution
atmos ai exec "List all production stacks"

# JSON output for parsing
atmos ai exec "Analyze VPC configuration" --format json > analysis.json

# CI/CD integration
result=$(atmos ai exec "Check for security issues" --format json)
if echo "$result" | jq -e '.success == false'; then
  exit 1
fi

# Pipe from stdin
echo "Validate production config" | atmos ai exec --format json

# Multi-turn automation
SESSION="deploy-$(date +%s)"
atmos ai exec "Plan deployment" --session "$SESSION" --format json
atmos ai exec "What are the risks?" --session "$SESSION" --format json
```

**Key Features:**
- **Multiple Output Formats:** JSON, text, markdown
- **Standard Exit Codes:** 0 (success), 1 (AI error), 2 (tool error)
- **Stdin Support:** Pipe prompts from other commands
- **Session Context:** Multi-turn conversations in scripts
- **File Output:** Direct file writing with `--output`
- **Provider Override:** Choose AI provider per execution

**JSON Output Structure:**
```json
{
  "success": true,
  "response": "Analysis complete...",
  "tool_calls": [
    {
      "tool": "atmos_list_stacks",
      "duration_ms": 45,
      "success": true,
      "result": {...}
    }
  ],
  "tokens": {
    "prompt": 120,
    "completion": 80,
    "total": 200,
    "cached": 50
  },
  "metadata": {
    "model": "claude-sonnet-4-20250514",
    "provider": "anthropic",
    "duration_ms": 1234
  }
}
```

**CI/CD Example:**
```yaml
# .github/workflows/ai-review.yml
- name: AI Infrastructure Review
  run: |
    result=$(atmos ai exec "Review infrastructure changes" --format json)
    echo "$result" | jq -r '.response' >> $GITHUB_STEP_SUMMARY

    # Fail on errors
    if echo "$result" | jq -e '.success == false'; then
      exit 1
    fi
```

**Use Cases:**
- Pre-deployment validation in CI/CD
- Automated security audits
- Infrastructure analysis reports
- Configuration validation pipelines
- Cost optimization analysis
- Compliance checking workflows

Learn more: [atmos ai exec documentation](/cli/commands/ai/exec)

### 10. Token Caching for Cost Savings

**NEW:** Atmos AI now supports **prompt caching** (token caching) to dramatically reduce API costs by reusing frequently-sent content like system prompts and project memory.

**Cost Savings:**
- **Anthropic:** 90% discount on cached tokens
- **OpenAI/Azure:** 50% discount on cached tokens
- **Gemini:** Free automatic caching
- **Grok:** 75% discount on cached tokens
- **Bedrock:** Up to 90% discount on cached tokens

**Real Example (Anthropic):**
- System prompt: 2,000 tokens
- ATMOS.md content: 8,000 tokens
- User message: 100 tokens

Without caching:
- Input: 10,100 tokens Ã— $3/1M = $0.0303
- **Total: $0.0378 per message**

With caching (90% cached):
- Cached: 10,000 tokens Ã— $0.30/1M = $0.0030 (90% discount)
- Fresh: 100 tokens Ã— $3/1M = $0.0003
- **Total: $0.0108 per message**

**Savings: 71%** ðŸ’°

**Provider Support:**

| Provider | Caching | Configuration |
|----------|---------|--------------|
| **Anthropic** | 90% discount | Configure in atmos.yaml |
| **OpenAI** | 50% discount | Automatic |
| **Gemini** | Free | Automatic |
| **Grok** | 75% discount | Automatic |
| **Bedrock** | Up to 90% | Automatic |
| **Azure OpenAI** | 50-100% | Automatic |

**Configuration (Anthropic):**

Most providers cache automatically with no configuration. For Anthropic, enable explicit cache markers:

```yaml
settings:
  ai:
    providers:
      anthropic:
        model: "claude-sonnet-4-20250514"
        cache:
          enabled: true              # Enable prompt caching
          cache_system_prompt: true  # Cache agent system prompt
          cache_project_memory: true # Cache ATMOS.md content
```

**How It Works:**
1. First message creates cache entries (normal cost)
2. Subsequent messages reuse cached content (90% discount)
3. Cache expires after 5 minutes of inactivity
4. Cache automatically refreshes when active

**JSON Output Includes Cache Metrics:**
```json
{
  "tokens": {
    "prompt": 120,
    "completion": 80,
    "total": 200,
    "cached": 50,           // Tokens read from cache
    "cache_creation": 10    // Tokens used to create cache
  }
}
```

Learn more: [Token Caching documentation](/ai/providers#token-caching-prompt-caching)

## Real-World Use Cases

### 1. New Team Member Onboarding

```bash
atmos ai chat --session onboarding

You: I just joined the team. Can you explain our stack structure?

AI: Welcome! Let me analyze your Atmos configuration...
    [Analyzes stacks automatically]

    Your organization uses a three-tier stack structure:

    1. Base stacks (catalog/stacks/base/)
       - Shared across all environments
       - Network, IAM, and security baselines

    2. Environment stacks (catalog/stacks/envs/)
       - dev, staging, prod configurations
       - Inherits from base, adds env-specific settings

    3. Deployment stacks (stacks/)
       - Actual deployment configurations
       - Combines base + env + region-specific settings

    Your naming convention: {org}-{env}-{region}-{stage}

    Example: acme-prod-use1-network

    Would you like me to walk through a specific stack?
```

### 2. Security Audit

```bash
atmos ai chat --agent security-auditor

You: Audit our production VPC security

AI: [Switches to Security Auditor agent]
    [Analyzes prod VPC configuration]

    Security Analysis for prod-use1-network:

    âœ… STRENGTHS:
    â€¢ VPC Flow Logs enabled (CloudWatch)
    â€¢ Private subnets properly configured
    â€¢ NAT Gateways in all AZs
    â€¢ Network ACLs configured

    âš ï¸  RECOMMENDATIONS:
    â€¢ Security group sg-12345 allows 0.0.0.0/0 on port 22
      Consider restricting SSH to VPN CIDR
    â€¢ No GuardDuty findings integration
      Recommend enabling for threat detection
    â€¢ S3 endpoint not configured
      Add for better security and cost savings

    Priority: Address SSH security group immediately

    Would you like me to generate a secure security group config?
```

### 3. Configuration Debugging

```bash
atmos ai chat --agent config-validator

You: My stack validation is failing with "undefined variable"

AI: [Switches to Config Validator]
    Let me validate your configuration...
    [Validates via LSP]

    Found the issue in stacks/prod/vpc.yaml:

    Line 15: var.vpc_cidr
    Problem: This variable isn't defined in your vars section

    Checking component definition...
    [Reads component file]

    Your component expects 'cidr_block' not 'vpc_cidr'

    Fix:
    ```yaml
    # Change line 15 from:
    vpc_cidr: var.vpc_cidr

    # To:
    cidr_block: "10.2.0.0/16"
    ```

    Would you like me to apply this fix?
```

### 4. Multi-Day Architecture Discussion

```bash
# Monday: Start discussion
atmos ai chat --session architecture-review
> "We need to design a new multi-region setup"
[2-hour discussion about regions, replication, disaster recovery...]

# Tuesday: Continue with full context
atmos ai chat --session architecture-review
> "What regions did we decide on yesterday?"
AI: "We discussed using us-east-1 (primary) and us-west-2 (DR)..."

# Wednesday: Reference earlier decisions
atmos ai chat --session architecture-review
> "Generate the stack configs based on our discussion"
AI: [Remembers all architectural decisions from Mon/Tue]
    [Generates configs matching the agreed design]
```

## Getting Started

### 1. Configure Atmos AI

Add to your `atmos.yaml`:

<File title="atmos.yaml">
```yaml
settings:
  ai:
    enabled: true
    default_provider: "anthropic"  # or openai, gemini, ollama, etc.

    # Configure your provider
    providers:
      anthropic:
        model: "claude-sonnet-4-20250514"
        api_key_env: "ANTHROPIC_API_KEY"
        max_tokens: 4096

      # Or use Ollama for complete privacy
      ollama:
        model: "llama3.3:70b"
        base_url: "http://localhost:11434/v1"
        # No API key needed!

    # Enable sessions
    sessions:
      enabled: true
      storage: "sqlite"
      path: ".atmos/sessions"
      retention_days: 30

    # Enable tools
    tools:
      enabled: true
      require_confirmation: true
      allowed_tools:
        - atmos_describe_*
        - atmos_list_*
        - file_read

    # Enable project memory
    memory:
      enabled: true
      file_path: "ATMOS.md"
      create_if_missing: true
```
</File>

### 2. Set Up Your Provider

**For Claude (Anthropic):**
```bash
export ANTHROPIC_API_KEY="sk-ant-..."
```

**For GPT (OpenAI):**
```bash
export OPENAI_API_KEY="sk-..."
```

**For Ollama (Local/Offline):**
```bash
# Install Ollama
curl -fsSL https://ollama.com/install.sh | sh

# Download a model
ollama pull llama3.3:70b

# Ready to use! (no API key needed)
```

See [AI Providers](/ai/providers) for all provider setup instructions.

### 3. Start Using Atmos AI

**Interactive Chat:**
```bash
# Start new session
atmos ai chat

# Named session
atmos ai chat --session infrastructure-review

# Specific provider
atmos ai chat --provider ollama

# Specific agent
atmos ai chat --agent security-auditor
```

**Quick Questions:**
```bash
# Single-shot query (interactive)
atmos ai ask "What components are in production?"

# With specific provider
atmos ai ask --provider bedrock "List all stacks"
```

**Non-Interactive Execution:**
```bash
# For scripting and automation
atmos ai exec "List all production stacks"

# JSON output for parsing
atmos ai exec "Analyze VPC config" --format json

# CI/CD integration
atmos ai exec "Security audit" --format json > report.json
```

**Session Management:**
```bash
# List sessions
atmos ai sessions list

# Delete old sessions
atmos ai sessions clean --older-than 30d
```

**Project Memory:**
```bash
# Initialize ATMOS.md
atmos ai memory init

# Edit in your $EDITOR
atmos ai memory edit

# View current memory
atmos ai memory view
```

**MCP Server (Claude Desktop):**
```bash
# Start MCP server
atmos mcp-server

# Or with HTTP transport
atmos mcp-server --transport http --port 3000
```

## TUI Keyboard Shortcuts

**Chat Interface:**
- **Ctrl+N** - Create new session with provider selection
- **Ctrl+L** - Switch between sessions
- **Ctrl+P** - Switch AI provider mid-conversation
- **Ctrl+A** - Switch AI agent
- **â†‘/â†“** - Navigate message history
- **Ctrl+J** - Add newline (alternative to Shift+Enter)
- **Ctrl+C** - Quit

**Session Manager:**
- **â†‘/â†“** or **j/k** - Navigate sessions
- **Enter** - Switch to selected session
- **d** - Delete session (with confirmation)
- **r** - Rename session
- **f** - Filter by provider (All/Claude/GPT/Gemini/Grok/Ollama/Bedrock/Azure)
- **n** - Create new session
- **Esc** - Return to chat

## Advanced Features

### Auto-Compact for Extended Conversations

Long conversations eventually hit provider token limits. Atmos AI solves this with **intelligent auto-compact**:

**How It Works:**
1. Monitors message count and token usage
2. Triggers when 75% of limit reached
3. Uses AI to summarize oldest 40% of conversation
4. Preserves recent messages for context continuity
5. Maintains semantic meaning while reducing tokens

**Configuration:**
```yaml
sessions:
  auto_compact:
    enabled: true  # Opt-in feature
    trigger_threshold: 0.75
    compact_ratio: 0.4
    preserve_recent: 10
    use_ai_summary: true
    summary_provider: anthropic
    summary_model: claude-3-5-haiku-20241022  # Fast & cheap
```

**Benefits:**
- âœ… Extend conversations indefinitely
- âœ… Reduce token costs by ~40%
- âœ… Preserve conversation semantics
- âœ… Automatic rate limit management

**User Experience:**
```
System: Compacting conversation (40 messages)...
System: Conversation compacted successfully (40 messages summarized, ~8000 tokens saved)
```

Learn more: [Sessions Documentation](/ai/sessions#auto-compact-extended-conversations)

### Conversation Checkpointing

Export and import AI chat sessions for team collaboration, backup, and knowledge sharing.

**Why Checkpointing?**
- Share troubleshooting sessions with your team
- Back up important architectural discussions
- Transfer knowledge to new team members
- Archive critical incident resolutions
- Resume conversations across different environments

**Export Sessions:**
```bash
# Export to JSON for programmatic use
atmos ai sessions export vpc-migration --output session.json

# Export to YAML for version control
atmos ai sessions export prod-incident --output incident.yaml --context

# Export to Markdown for documentation
atmos ai sessions export architecture-review --output docs/architecture.md
```

**Import Sessions:**
```bash
# Import session from teammate
atmos ai sessions import colleague-session.json

# Import with custom name
atmos ai sessions import backup.yaml --name restored-session

# Overwrite existing session
atmos ai sessions import session.json --overwrite
```

**Checkpoint Contents:**
- âœ… Complete message history with timestamps
- âœ… Session metadata (model, provider, settings)
- âœ… Project context (ATMOS.md, working directory)
- âœ… Session statistics (message counts, token usage)
- âœ… Version compatibility information

**Supported Formats:**
- **JSON** - Machine-readable, perfect for automation and archival
- **YAML** - Human-readable, great for version control and git
- **Markdown** - Beautiful reports for documentation and sharing

**Team Collaboration Workflow:**
```bash
# Developer A: Export troubleshooting session
atmos ai sessions export db-migration-issue \
  --output db-migration.json \
  --context

# Share file via git/Slack/email

# Developer B: Import and continue conversation
atmos ai sessions import db-migration.json \
  --name db-migration-collab

atmos ai chat --session db-migration-collab
> "Let's try a different migration approach..."
```

**Use Cases:**
- **Team Collaboration** - Share complex troubleshooting sessions
- **Knowledge Transfer** - Onboard new team members with real examples
- **Incident Response** - Archive incident resolutions for retrospectives
- **Architecture Decisions** - Document reasoning with full AI context
- **Cross-Project Learning** - Reuse solutions from other projects

**Session Management:**
```bash
# List all sessions
atmos ai sessions list

# Clean old sessions (30 days default)
atmos ai sessions clean --older-than 30d

# Clean sessions older than 7 days
atmos ai sessions clean --older-than 7d
```

Learn more: [Sessions Documentation](/cli/commands/ai/sessions)

### GitHub Actions Integration

Automate infrastructure analysis, PR reviews, and security scans directly in your CI/CD pipelines with the official Atmos AI GitHub Action.

**Why GitHub Actions?**
- Automated PR reviews on every pull request
- Continuous security scanning
- Cost impact analysis
- Configuration validation before merge
- Team-wide visibility via PR comments

**Quick Start:**
```yaml
name: AI PR Review

on:
  pull_request:
    types: [opened, synchronize]

jobs:
  ai-review:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - uses: cloudposse/atmos/.github/actions/atmos-ai@main
        with:
          prompt: |
            Review this PR for:
            1. Configuration errors
            2. Security issues
            3. Best practices violations
            4. Breaking changes
          provider: anthropic
          api-key: ${{ secrets.ANTHROPIC_API_KEY }}
          post-comment: true
```

**Use Cases:**
- **PR Reviews** - Catch issues before merge with AI-powered analysis
- **Security Scans** - Daily automated security audits
- **Cost Analysis** - Estimate cost impact of infrastructure changes
- **Compliance Checks** - Validate against company policies

**Key Features:**
- âœ… Works with all 7 AI providers
- âœ… Posts analysis as PR comments
- âœ… JSON output for automation
- âœ… Session support for multi-turn analysis
- âœ… Token usage tracking
- âœ… Automatic Atmos installation
- âœ… Configurable failure behavior

**Example PR Comment:**
```
ðŸ¤– Atmos AI Code Review

### AI Response

Configuration looks good overall. Found 2 warnings:

WARNING: Stack prod-east-vpc uses outdated instance types (t2.micro)
  Recommendation: Upgrade to t3.micro for better performance/cost

WARNING: Missing required tags on 3 resources
  Required tags: Environment, Owner, CostCenter

ðŸ“Š Execution Details
| Metric | Value |
|--------|-------|
| Status | âœ… Success |
| Tool Calls | 5 |
| Tokens Used | 1,234 |
| Cached Tokens | 890 (72%) |
```

**Advanced: Multi-Provider Analysis**
```yaml
strategy:
  matrix:
    provider: [anthropic, openai, gemini]
steps:
  - uses: cloudposse/atmos/.github/actions/atmos-ai@main
    with:
      provider: ${{ matrix.provider }}
      prompt: "Review infrastructure changes"
```

**Cost Optimization:**
The action automatically benefits from token caching, reducing costs by 50-90% depending on the provider.

Learn more: [GitHub Actions Integration](/integrations/github-actions/atmos-ai)

### Agent Marketplace (Coming Soon)

Install community-created specialized agents:

```bash
# Install custom agent
atmos ai agent install github.com/cloudposse/agent-cost-analyzer

# Use it
atmos ai chat --agent cost-analyzer
> "Analyze infrastructure costs across all environments"
```

**Coming features:**
- Version management
- Agent dependencies
- Private agent registries
- Agent composition

## Security & Privacy

### Data Privacy Options

**Complete Privacy (Ollama):**
- 100% local processing
- No data sent to external services
- HIPAA/GDPR compliant out-of-the-box
- Air-gapped environment support

**Enterprise Privacy (Bedrock/Azure):**
- Data stays in your cloud (AWS/Azure)
- VPC/VNet isolation
- Customer-managed encryption keys
- Compliance certifications (SOC2, HIPAA, ISO)

**Cloud Providers (Claude/GPT/Gemini/Grok):**
- Data sent to provider APIs
- Review provider privacy policies
- Enable zero-data retention when available
- Use for non-sensitive workloads

### Permission Controls

**Recommended Production Settings:**
```yaml
tools:
  # Read-only by default
  allowed_tools:
    - atmos_describe_*
    - atmos_list_*

  # Block destructive operations
  blocked_tools:
    - atmos_terraform_destroy
    - atmos_terraform_apply

  # Enable audit logging
  audit:
    enabled: true
    path: .atmos/ai-audit.log
```

**Best Practices:**
1. Use enterprise providers (Bedrock/Azure) for production
2. Enable audit logging
3. Configure tool restrictions
4. Review `.atmosignore` for sensitive files
5. Use Ollama for sensitive workloads
6. Regular session cleanup

## Performance

**Session Operations:**
- Create session: <10ms
- Load session: <50ms
- Add message: <10ms
- List sessions: <100ms

**Tool Execution:**
- Read operations: Varies by tool
- Validation (LSP): <1s
- Stack analysis: Varies by complexity

**AI Response Times:**
- Streaming: First token in 500ms-2s
- Full response: Varies by provider and complexity
- Ollama: Depends on hardware (GPU recommended)

## What's Next?

We're continuously improving Atmos AI. Recent completions and upcoming features:

### Recently Completed âœ…
- âœ… **Non-Interactive Execution** (`atmos ai exec`) - Automation and CI/CD support
- âœ… **Structured JSON Output** - Machine-parseable responses with metadata
- âœ… **Standard Exit Codes** - Reliable automation with proper error handling
- âœ… **Stdin Support** - Shell integration and piping
- âœ… **Token Caching (Prompt Caching)** - Save up to 90% on API costs with automatic caching
- âœ… **Conversation Checkpointing** - Export/import sessions for team collaboration and backup
- âœ… **GitHub Actions Integration** - Official action for automated PR reviews and CI/CD workflows

### Short-term (Next 3 Months)
- **Directory Scoping** - Auto-discovery with .gitignore support
- **Agent Marketplace** - Install community agents
- **Enhanced LSP** - More language servers (HCL, JSON Schema)
- **Advanced Analytics** - Token usage tracking, cost analysis
- **Auto-Fix Suggestions** - AI-powered configuration fixes

### Medium-term (3-6 Months)
- **Multi-Agent Workflows** - Agent delegation and collaboration
- **Enhanced Memory** - Automatic memory updates from conversations
- **IDE Plugins** - Native VSCode/JetBrains integration
- **Team Collaboration** - Shared sessions across teams

### Long-term (6-12 Months)
- **Private Agent Registries** - Company-specific agents
- **Advanced Security** - Agent sandboxing, GPG signatures
- **Centralized Management** - Organization-wide policies
- **Advanced Workflows** - Task decomposition, parallel execution

## Learn More

**Documentation:**
- [Configuration Guide](/ai/configuration) - Complete configuration reference
- [AI Providers](/ai/providers) - All 7 providers with setup instructions
- [Tool System](/ai/tools) - Tool execution and permissions
- [AI Agents](/ai/agents) - Built-in agents and agent system
- [Sessions](/ai/sessions) - Session management and auto-compact
- [Project Memory](/ai/memory) - ATMOS.md documentation
- [MCP Server](/ai/mcp-server) - Claude Desktop integration
- [Claude Code Integration](/ai/claude-code-integration) - IDE integration
- [Troubleshooting](/ai/troubleshooting) - Common issues and solutions

**Related Links:**
- [Atmos Documentation](https://atmos.tools)
- [Model Context Protocol](https://modelcontextprotocol.io)
- [Ollama](https://ollama.com)

**Get Involved:**
- [GitHub Issues](https://github.com/cloudposse/atmos/issues)
- [Community Discussions](https://github.com/cloudposse/atmos/discussions)

---

Happy infrastructure engineering! ðŸš€

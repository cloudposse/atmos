---
title: Atmos AI Assistant
sidebar_position: 1
sidebar_label: AI Assistant
sidebar_class_name: hidden
description: AI-powered assistance for Atmos infrastructure management
id: ai
---
import Terminal from '@site/src/components/Terminal'
import File from '@site/src/components/File'
import DocCardList from '@theme/DocCardList'

# Atmos AI Assistant

The Atmos AI Assistant is an AI-powered terminal agent that helps with Atmos infrastructure management. It provides intelligent assistance with understanding Atmos concepts, analyzing configurations, troubleshooting issues, and learning best practices.

## Features

### Conversation Management
- **Interactive Chat Interface**: Terminal-based chat session for extended conversations
- **Persistent Sessions**: Save and resume conversations across CLI invocations
- **Message History**: Complete conversation history stored locally in SQLite
- **Named Sessions**: Organize conversations by topic or project
- **Session Management**: List, clean, and manage your conversation sessions

### AI Capabilities
- **Command-line Q&A**: Ask questions directly from the command line
- **Context-aware Help**: Get help on specific Atmos topics
- **Configuration Analysis**: The AI has knowledge of your Atmos setup
- **Best Practice Guidance**: Receive recommendations for optimal configurations

### Tool Execution
- **Automated Queries**: AI can automatically inspect your infrastructure configuration
- **Read-only Tools**: Safe execution of describe, list, and validate operations
- **Permission System**: Granular control over what tools the AI can execute
- **Smart Prompts**: User confirmation for sensitive operations

### Project Memory
- **Persistent Context**: AI remembers project-specific patterns and conventions
- **Markdown-Based**: Simple `ATMOS.md` file stores project knowledge
- **Customizable Sections**: Control what context is shared with AI
- **Team Collaboration**: Share memory file with your team via version control

## Quick Start

Enable AI features in your `atmos.yaml`:

<File title="atmos.yaml">
```yaml
settings:
  ai:
    enabled: true
    provider: "anthropic"  # or "openai", "gemini", "grok"
    api_key_env: "ANTHROPIC_API_KEY"

    # Optional: Enable persistent sessions
    sessions:
      enabled: true              # Save conversation history
      storage: "sqlite"          # Local SQLite storage
      path: ".atmos/sessions"    # Storage location
      retention_days: 30         # Auto-cleanup after 30 days

    # Optional: Enable tool execution
    tools:
      enabled: true              # Allow AI to query your infrastructure
      require_confirmation: true # Prompt before executing tools
      allowed_tools:             # Tools that don't need confirmation
        - atmos_describe_component
        - atmos_list_stacks

    # Optional: Enable project memory
    memory:
      enabled: true              # Remember project-specific context
      file_path: "ATMOS.md"      # Memory file location
      create_if_missing: true    # Auto-create template
      auto_update: false         # Manual updates only (recommended)

    # Optional: Performance tuning
    timeout_seconds: 60         # Default: 60
    max_context_files: 10       # Default: 10
    max_context_lines: 500      # Default: 500
```
</File>

Set your API key:

<Terminal title="shell">
```bash
export ANTHROPIC_API_KEY="your-api-key-here"
```
</Terminal>

Start using the AI assistant:

<Terminal title="atmos ai chat">
```bash
# Interactive chat
atmos ai chat

# Quick question
atmos ai ask "What components are available?"

# Topic help
atmos ai help stacks
```
</Terminal>

## What the AI Can Help With

### Understanding Concepts
- Atmos architecture and core concepts
- Stack vs component relationships
- Template functions and usage
- Workflow orchestration patterns

### Configuration Analysis
- Reviewing component configurations
- Understanding stack inheritance
- Debugging configuration issues
- Optimizing performance

### Best Practices
- Stack organization strategies
- Component reusability patterns
- Template usage guidelines
- Validation and testing approaches

### Troubleshooting
- Error message interpretation
- Common configuration issues
- Debugging workflows
- Performance optimization

## Supported Providers

Atmos AI Assistant supports multiple AI providers:

| Provider | Default Model | API Key Environment Variable | Notes |
|----------|---------------|------------------------------|-------|
| **Anthropic (Claude)** | `claude-3-5-sonnet-20241022` | `ANTHROPIC_API_KEY` | Default provider, advanced reasoning |
| **OpenAI (GPT)** | `gpt-4o` | `OPENAI_API_KEY` | Widely available, strong general capabilities |
| **Google (Gemini)** | `gemini-2.0-flash-exp` | `GEMINI_API_KEY` | Fast responses, larger context window |
| **xAI (Grok)** | `grok-beta` | `XAI_API_KEY` | OpenAI-compatible, real-time knowledge |

You can switch providers by changing the `provider` field in your configuration.

## Example Use Cases

### New User Onboarding

<Terminal title="shell">
```bash
atmos ai ask "I'm new to Atmos. What should I know?"
atmos ai help stacks
atmos ai ask "How do I create my first component?"
```
</Terminal>

### Configuration Review

<Terminal title="shell">
```bash
atmos ai ask "Review my vpc component configuration"
atmos ai ask "What are potential issues with my stack structure?"
atmos ai ask "How can I optimize my template usage?"
```
</Terminal>

### Troubleshooting

<Terminal title="shell">
```bash
atmos ai ask "I'm getting a validation error for component X. How do I fix it?"
atmos ai ask "My template rendering is failing. What could be wrong?"
atmos ai ask "How do I debug workflow execution issues?"
```
</Terminal>

### Learning Advanced Features

<Terminal title="shell">
```bash
atmos ai help workflows
atmos ai ask "How do I use Gomplate functions in my templates?"
atmos ai ask "What's the best way to handle secrets in Atmos?"
```
</Terminal>

## Security and Privacy

- **API Key Security**: Store your API keys securely and never commit them to version control
- **Configuration Privacy**: The AI assistant does not store or transmit your configuration data beyond the current session
- **Local Processing**: All processing is done through the provider's API; no data is stored locally by the AI features
- **Provider Terms**: Your usage is subject to the terms of service of your chosen provider (Anthropic, OpenAI, Google, or xAI)

## Limitations

- **AI Knowledge Cutoff**: The AI's knowledge of Atmos is current as of its training date
- **API Dependencies**: Requires internet connection and valid API key for your chosen provider
- **Configuration Context**: The AI works with your current Atmos configuration but cannot make direct changes
- **Rate Limits**: Subject to your provider's API rate limits and usage policies

## Related Documentation

<DocCardList/>

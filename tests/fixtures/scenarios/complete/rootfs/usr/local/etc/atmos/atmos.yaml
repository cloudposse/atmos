# CLI config is loaded from the following locations (from lowest to highest priority):
# system dir ('/usr/local/etc/atmos' on Linux, '%LOCALAPPDATA%/atmos' on Windows)
# home dir (~/.atmos)
# current directory
# ENV vars
# Command-line arguments
#
# It supports POSIX-style Globs for file names/paths (double-star '**' is supported)
# https://en.wikipedia.org/wiki/Glob_(programming)

# Base path for components, stacks and workflows configurations.
# Can also be set using 'ATMOS_BASE_PATH' ENV var, or '--base-path' command-line argument.
# Supports both absolute and relative paths.
# If not provided or is an empty string, 'components.terraform.base_path', 'components.helmfile.base_path', 'stacks.base_path' and 'workflows.base_path'
# are independent settings (supporting both absolute and relative paths).
# If 'base_path' is provided, 'components.terraform.base_path', 'components.helmfile.base_path', 'stacks.base_path' and 'workflows.base_path'
# are considered paths relative to 'base_path'.
base_path: ""

components:
  terraform:
    # Optional `command` specifies the executable to be called by `atmos` when running Terraform commands
    # If not defined, `terraform` is used
    # Examples:
    # command: terraform
    # command: /usr/local/bin/terraform
    # command: /usr/local/bin/terraform-1.8
    # command: tofu
    # command: /usr/local/bin/tofu-1.7.1
    # Can also be set using 'ATMOS_COMPONENTS_TERRAFORM_COMMAND' ENV var, or '--terraform-command' command-line argument
    command: terraform
    # Can also be set using 'ATMOS_COMPONENTS_TERRAFORM_BASE_PATH' ENV var, or '--terraform-dir' command-line argument
    # Supports both absolute and relative paths
    base_path: "components/terraform"
    # Can also be set using 'ATMOS_COMPONENTS_TERRAFORM_APPLY_AUTO_APPROVE' ENV var
    apply_auto_approve: false
    # Can also be set using 'ATMOS_COMPONENTS_TERRAFORM_DEPLOY_RUN_INIT' ENV var, or '--deploy-run-init' command-line argument
    deploy_run_init: true
    # Can also be set using 'ATMOS_COMPONENTS_TERRAFORM_INIT_RUN_RECONFIGURE' ENV var, or '--init-run-reconfigure' command-line argument
    init_run_reconfigure: true
    # Can also be set using 'ATMOS_COMPONENTS_TERRAFORM_AUTO_GENERATE_BACKEND_FILE' ENV var, or '--auto-generate-backend-file' command-line argument
    auto_generate_backend_file: false
  helmfile:
    # Can also be set using 'ATMOS_COMPONENTS_HELMFILE_BASE_PATH' ENV var, or '--helmfile-dir' command-line argument
    # Supports both absolute and relative paths
    base_path: "components/helmfile"
    # Can also be set using 'ATMOS_COMPONENTS_HELMFILE_USE_EKS' ENV var
    # If not specified, defaults to 'true'
    use_eks: true
    # Can also be set using 'ATMOS_COMPONENTS_HELMFILE_KUBECONFIG_PATH' ENV var
    kubeconfig_path: "/dev/shm"
    # Can also be set using 'ATMOS_COMPONENTS_HELMFILE_HELM_AWS_PROFILE_PATTERN' ENV var
    helm_aws_profile_pattern: "{namespace}-{tenant}-gbl-{stage}-helm"
    # Can also be set using 'ATMOS_COMPONENTS_HELMFILE_CLUSTER_NAME_PATTERN' ENV var
    cluster_name_pattern: "{namespace}-{tenant}-{environment}-{stage}-eks-cluster"

stacks:
  # Can also be set using 'ATMOS_STACKS_BASE_PATH' ENV var, or '--config-dir' and '--stacks-dir' command-line arguments
  # Supports both absolute and relative paths
  base_path: "stacks"
  # Can also be set using 'ATMOS_STACKS_INCLUDED_PATHS' ENV var (comma-separated values string)
  included_paths:
    - "orgs/**/*"
  # Can also be set using 'ATMOS_STACKS_EXCLUDED_PATHS' ENV var (comma-separated values string)
  excluded_paths:
    - "**/_defaults.yaml"
  # Can also be set using 'ATMOS_STACKS_NAME_PATTERN' ENV var
  # name_pattern: "{tenant}-{environment}-{stage}"
  # Can also be set using 'ATMOS_STACKS_NAME_TEMPLATE' ENV var
  name_template: "{{.vars.tenant}}-{{.vars.environment}}-{{.vars.stage}}"

workflows:
  # Can also be set using 'ATMOS_WORKFLOWS_BASE_PATH' ENV var, or '--workflows-dir' command-line argument
  # Supports both absolute and relative paths
  base_path: "stacks/workflows"

logs:
  # Can also be set using 'ATMOS_LOGS_FILE' ENV var, or '--logs-file' command-line argument
  # File or standard file descriptor to write logs to
  # Logs can be written to any file or any standard file descriptor, including `/dev/stdout`, `/dev/stderr` and `/dev/null`
  file: "/dev/stderr"
  # Supported log levels: Trace, Debug, Info, Warning, Off
  # Can also be set using 'ATMOS_LOGS_LEVEL' ENV var, or '--logs-level' command-line argument
  level: Info

# Custom CLI commands
commands:
  - name: tf
    description: Execute 'terraform' commands
    # subcommands
    commands:
      - name: plan
        description: This command plans terraform components
        arguments:
          - name: component
            description: Name of the component
        flags:
          - name: stack
            shorthand: s
            description: Name of the stack
            required: true
        env:
          - key: ENV_VAR_1
            value: ENV_VAR_1_value
          - key: ENV_VAR_2
            # 'valueCommand' is an external command to execute to get the value for the ENV var
            # Either 'value' or 'valueCommand' can be specified for the ENV var, but not both
            valueCommand: echo ENV_VAR_2_value
        # steps support Go templates
        steps:
          - atmos terraform plan {{ .Arguments.component }} -s {{ .Flags.stack }}
  - name: terraform
    description: Execute 'terraform' commands
    # subcommands
    commands:
      - name: provision
        description: This command provisions terraform components
        arguments:
          - name: component
            description: Name of the component
        flags:
          - name: stack
            shorthand: s
            description: Name of the stack
            required: true
        # ENV var values support Go templates
        env:
          - key: ATMOS_COMPONENT
            value: "{{ .Arguments.component }}"
          - key: ATMOS_STACK
            value: "{{ .Flags.stack }}"
        steps:
          - atmos terraform plan $ATMOS_COMPONENT -s $ATMOS_STACK
          - atmos terraform apply $ATMOS_COMPONENT -s $ATMOS_STACK
  - name: show
    description: Execute 'show' commands
    # subcommands
    commands:
      - name: component
        description: Execute 'show component' command
        arguments:
          - name: component
            description: Name of the component
        flags:
          - name: stack
            shorthand: s
            description: Name of the stack
            required: true
        # ENV var values support Go templates and have access to {{ .ComponentConfig.xxx.yyy.zzz }} Go template variables
        env:
          - key: ATMOS_COMPONENT
            value: "{{ .Arguments.component }}"
          - key: ATMOS_STACK
            value: "{{ .Flags.stack }}"
          - key: ATMOS_TENANT
            value: "{{ .ComponentConfig.vars.tenant }}"
          - key: ATMOS_STAGE
            value: "{{ .ComponentConfig.vars.stage }}"
          - key: ATMOS_ENVIRONMENT
            value: "{{ .ComponentConfig.vars.environment }}"
          - key: ATMOS_IS_PROD
            value: "{{ .ComponentConfig.settings.config.is_prod }}"
        # If a custom command defines 'component_config' section with 'component' and 'stack', 'atmos' generates the config for the component in the stack
        # and makes it available in {{ .ComponentConfig.xxx.yyy.zzz }} Go template variables,
        # exposing all the component sections (which are also shown by 'atmos describe component' command)
        component_config:
          component: "{{ .Arguments.component }}"
          stack: "{{ .Flags.stack }}"
        # Steps support using Go templates and can access all configuration settings (e.g. {{ .ComponentConfig.xxx.yyy.zzz }})
        # Steps also have access to the ENV vars defined in the 'env' section of the 'command'
        steps:
          - 'echo Atmos component from argument: "{{ .Arguments.component }}"'
          - 'echo ATMOS_COMPONENT: "$ATMOS_COMPONENT"'
          - 'echo Atmos stack: "{{ .Flags.stack }}"'
          - 'echo Terraform component: "{{ .ComponentConfig.component }}"'
          - 'echo Backend S3 bucket: "{{ .ComponentConfig.backend.bucket }}"'
          - 'echo Terraform workspace: "{{ .ComponentConfig.workspace }}"'
          - 'echo Namespace: "{{ .ComponentConfig.vars.namespace }}"'
          - 'echo Tenant: "{{ .ComponentConfig.vars.tenant }}"'
          - 'echo Environment: "{{ .ComponentConfig.vars.environment }}"'
          - 'echo Stage: "{{ .ComponentConfig.vars.stage }}"'
          - 'echo settings.spacelift.workspace_enabled: "{{ .ComponentConfig.settings.spacelift.workspace_enabled }}"'
          - 'echo Dependencies: "{{ .ComponentConfig.deps }}"'
          - 'echo settings.config.is_prod: "{{ .ComponentConfig.settings.config.is_prod }}"'
          - 'echo ATMOS_IS_PROD: "$ATMOS_IS_PROD"'

  - name: set-eks-cluster
    description: |
      Download 'kubeconfig' and set EKS cluster.

      Example usage:
        atmos set-eks-cluster eks/cluster -s tenant1-ue1-dev -r admin
        atmos set-eks-cluster eks/cluster -s tenant2-uw2-prod --role reader
    verbose: false # Set to `true` to see verbose outputs
    arguments:
      - name: component
        description: Name of the component
    flags:
      - name: stack
        shorthand: s
        description: Name of the stack
        required: true
      - name: role
        shorthand: r
        description: IAM role to use
        required: true
    # If a custom command defines 'component_config' section with 'component' and 'stack',
    # Atmos generates the config for the component in the stack
    # and makes it available in {{ .ComponentConfig.xxx.yyy.zzz }} Go template variables,
    # exposing all the component sections (which are also shown by 'atmos describe component' command)
    component_config:
      component: "{{ .Arguments.component }}"
      stack: "{{ .Flags.stack }}"
    env:
      - key: KUBECONFIG
        value: /dev/shm/kubecfg.{{ .Flags.stack }}-{{ .Flags.role }}
    steps:
      - >
        aws
        --profile {{ .ComponentConfig.vars.namespace }}-{{ .ComponentConfig.vars.tenant }}-gbl-{{ .ComponentConfig.vars.stage }}-{{ .Flags.role }}
        --region {{ .ComponentConfig.vars.region }}
        eks update-kubeconfig
        --name={{ .ComponentConfig.vars.namespace }}-{{ .Flags.stack }}-eks-cluster
        --kubeconfig="${KUBECONFIG}"
        > /dev/null
      - chmod 600 ${KUBECONFIG}
      - echo ${KUBECONFIG}

  - name: describe
    description: "Execute 'describe' commands"
    # subcommands
    commands:
      - name: eks
        description: "Execute 'describe eks' commands"
        # subcommands
        commands:
          - name: upgrade
            description: "Describe the steps on how to upgrade an EKS cluster to the next Kubernetes version. Usage: atmos describe eks upgrade <eks_component> -s <stack>"
            arguments:
              - name: component
                description: Name of the EKS component
            flags:
              - name: stack
                shorthand: s
                description: Name of the stack
                required: true
              - name: role
                shorthand: r
                description: Role to assume to connect to the cluster
                required: false
            # If a custom command defines 'component_config' section with 'component' and 'stack',
            # Atmos generates the config for the component in the stack
            # and makes it available in {{ .ComponentConfig.xxx.yyy.zzz }} Go template variables,
            # exposing all the component sections (which are also shown by 'atmos describe component' command)
            component_config:
              component: "{{ .Arguments.component }}"
              stack: "{{ .Flags.stack }}"
            env:
              - key: KUBECONFIG
                value: /dev/shm/kubecfg-eks-upgrade.{{ .Flags.stack }}
            steps:
              # https://jqlang.github.io/jq/manual
              # https://github.com/jqlang/jq/wiki/FAQ
              # https://developer.zendesk.com/documentation/integration-services/developer-guide/jq-cheat-sheet
              # https://earthly.dev/blog/jq-select
              # https://ingernet.github.io/bash/jq/2020/04/28/jq-bash-expand-variables.html
              # https://stackoverflow.com/questions/39139107/how-to-format-a-json-string-as-a-table-using-jq
              # https://stackoverflow.com/questions/57298373/print-colored-raw-output-with-jq-on-terminal
              # https://stackoverflow.com/questions/23118341/how-to-get-key-names-from-json-using-jq
              # https://stackoverflow.com/questions/42011086/merge-arrays-of-json
              # https://www.baeldung.com/linux/jq-passing-bash-variables
              # https://learnk8s.io/blog/kubectl-productivity
              # https://stackoverflow.com/questions/65421774/kubernetes-list-all-containers-that-are-not-running
              # https://blog.cubieserver.de/2021/list-all-failed-pods-in-a-namespace-with-kubectl
              # https://gist.github.com/ernoaapa/c8ef4973aa30104cfc898ec94b7e3f29
              # https://helm.sh/docs/topics/kubernetes_apis
              # https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle
              # https://github.com/Masterminds/sprig
              # http://masterminds.github.io/sprig
              # https://docs.aws.amazon.com/cli/latest/reference/eks/describe-cluster.html
              # https://docs.aws.amazon.com/cli/latest/userguide/cli-usage-filter.html
              # https://jmespath.org
              - |
                # Set the environment
                color_red="\u001b[31m"
                color_green="\u001b[32m"
                color_yellow="\u001b[33m"
                color_blue="\u001b[34m"
                color_magenta="\u001b[35m"
                color_cyan="\u001b[36m"
                color_black="\u001b[30m"
                color_white="\u001b[37m"
                color_reset="\u001b[0m"

                # Check the requirements
                command -v aws >/dev/null 2>&1 || { echo -e >&2 "\n${color_red}'aws' is required but it's not installed.${color_reset}"; exit 1; }
                command -v kubectl >/dev/null 2>&1 || { echo -e >&2 "\n${color_red}'kubectl' is required but it's not installed.${color_reset}"; exit 1; }
                command -v helm >/dev/null 2>&1 || { echo -e >&2 "\n${color_red}'helm' is required but it's not installed.${color_reset}"; exit 1; }
                command -v jq >/dev/null 2>&1 || { echo -e >&2 "\n${color_red}'jq' is required but it's not installed.${color_reset}"; exit 1; }
                command -v yq >/dev/null 2>&1 || { echo -e >&2 "\n${color_red}'yq' is required but it's not installed.${color_reset}"; exit 1; }
                command -v pluto >/dev/null 2>&1 || { echo -e >&2 "\n${color_red}'pluto' is required but it's not installed.${color_reset}"; exit 1; }
                command -v awk >/dev/null 2>&1 || { echo -e >&2 "\n${color_red}'awk' is required but it's not installed.${color_reset}"; exit 1; }
                command -v sed >/dev/null 2>&1 || { echo -e >&2 "\n${color_red}'sed' is required but it's not installed.${color_reset}"; exit 1; }
                command -v tr >/dev/null 2>&1 || { echo -e >&2 "\n${color_red}'tr' is required but it's not installed.${color_reset}"; exit 1; }

                # Set the role to assume to connect to the cluster
                role={{ .Flags.role }}
                if [[ -z "$role" ]]; then
                  role=admin
                fi

                # Download kubeconfig and connect to the cluster
                echo -e "\nConnecting to EKS cluster ${color_cyan}{{ .Flags.stack }}${color_reset} and downloading kubeconfig..."
                aws \
                    --profile {{ .ComponentConfig.vars.namespace }}-{{if (index .ComponentConfig.vars "tenant") }}{{ .ComponentConfig.vars.tenant }}-gbl-{{ .ComponentConfig.vars.stage }}{{else}}gbl-{{ .ComponentConfig.vars.stage }}{{end}}-${role} \
                    --region {{ .ComponentConfig.vars.region }} \
                    eks update-kubeconfig \
                    --name={{ .ComponentConfig.vars.namespace }}-{{ .Flags.stack }}-eks-cluster \
                    --kubeconfig="${KUBECONFIG}"
                chmod 600 ${KUBECONFIG}

                # Check connectivity to the cluster
                kubectl version -o json 2>&1>/dev/null
                retVal=$?
                if [ $retVal -ne 0 ]; then
                  echo -e "${color_red}\nCould not connect to the cluster.\nIf the cluster is provisioned in private subnets or only allows private access, make sure you are connected to the VPN.\n${color_reset}"
                  exit $retVal
                fi

                # Get the current Kubernetes version from the cluster
                current_k8s_version_str=$(kubectl version -o json 2>/dev/null | jq '(.serverVersion.major + "." + .serverVersion.minor)' | sed 's/[+\"]//g')
                current_k8s_version=$(echo ${current_k8s_version_str} | jq 'tonumber')
                echo -e "\nThe cluster is running Kubernetes version ${current_k8s_version}"

                # Get all the supported Kubernetes versions from AWS EKS
                supported_eks_k8s_versions=$(aws eks describe-addon-versions | jq -r '[ .addons[].addonVersions[].compatibilities[].clusterVersion ] | unique | sort')
                supported_eks_k8s_versions_csv=$(echo ${supported_eks_k8s_versions} | jq -r 'join(", ")')
                echo -e "AWS EKS currently supports Kubernetes versions ${supported_eks_k8s_versions_csv}"

                # Calculate the next Kubernetes version that the cluster can be upgraded to
                next_k8s_version=$(echo ${supported_eks_k8s_versions} | jq -r --arg current_k8s_version "${current_k8s_version}" 'map(select((. |= tonumber) > ($current_k8s_version | tonumber)))[0]')

                # Check if the cluster can be upgraded
                upgrade_needed=false
                if [[ ! -z "$next_k8s_version" ]] && (( $(echo $next_k8s_version $current_k8s_version | awk '{if ($1 > $2) print 1;}') )) ; then
                  upgrade_needed=true
                else
                fi
                if [ ${upgrade_needed} = false ]; then
                  echo -e "${color_green}\nThe cluster is running the latest supported Kubernetes version ${current_k8s_version}\n${color_reset}"
                  exit 0
                fi

                # Describe the upgrade process
                echo -e "${color_green}\nThe cluster can be upgraded to the next Kubernetes version ${next_k8s_version}${color_reset}"

                # Describe what will be checked before the upgrade
                describe_what_will_be_checked="
                  \nBefore upgrading the cluster to Kubernetes ${next_k8s_version}, we'll check the following:

                  - Pods and containers that are not ready or crashing
                      https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle

                  - Helm releases with removed Kubernetes API versions
                      https://kubernetes.io/docs/reference/using-api/deprecation-policy
                      https://helm.sh/docs/topics/kubernetes_apis

                  - EKS add-ons versions
                      https://docs.aws.amazon.com/eks/latest/userguide/eks-add-ons.html
                "
                echo -e "${describe_what_will_be_checked}"

                echo -e "${color_cyan}\nPress Enter to continue ...${color_reset}"
                read -r

                # Show all Pods that are not in 'Running' state
                echo -e "\nChecking for Pods that are not in 'Running' state...\n"
                kubectl get pods -A | grep -Ev '([0-9]+)/\1'

                # Show failed or not ready containers
                echo -e "\nChecking for failing containers..."
                failing_containers=$(kubectl get pods -A -o json | jq '[ .items[].status.containerStatuses[].state | select(has("waiting")) | .waiting ]')
                failing_containers_count=$(echo ${failing_containers} | jq  'length')
                if [[ "$failing_containers_count" > 0 ]]; then
                  echo -e "${color_red}\nThere are ${failing_containers_count} failing container(s) on the cluster:\n${color_reset}"
                  echo ${failing_containers} | jq -r 'def red: "\u001b[31m"; def reset: "\u001b[0m"; (.[] | [ red + .message + reset ]) | @tsv'
                  echo -e "\nAlthough the cluster can be upgraded to the next Kubernetes version even with the failing Pods and containers, it's recommended to fix all the issues before upgrading.\n"
                else
                  echo -e "${color_green}\nThere are no failing containers on the cluster\n${color_reset}"
                fi

                echo -e "${color_cyan}\nPress Enter to continue ...${color_reset}"
                read -r

                # Show Helm releases with removed Kubernetes API versions
                echo -e "\nChecking for Helm releases with removed Kubernetes API versions...\n"
                releases_with_removed_versions=$(pluto detect-helm --output json --only-show-removed --target-versions k8s=v${next_k8s_version} 2>/dev/null | jq 'select(has("items")) | [ .items[] ]')
                releases_with_removed_versions_count=$(echo ${releases_with_removed_versions} | jq  'length')
                if [[ -z "$releases_with_removed_versions_count" ]] || [[ "$releases_with_removed_versions_count" = 0 ]]; then
                  echo -e "${color_green}\nAll Helm releases are up to date and ready for Kubernetes ${next_k8s_version}${color_reset}"
                else
                  echo -e "${color_red}\nThere are Helm releases with API versions removed in Kubernetes ${next_k8s_version}\n${color_reset}"
                  pluto detect-helm --output wide --only-show-removed --target-versions k8s=v${next_k8s_version} 2>/dev/null
                  helm_list_filter=$(echo ${releases_with_removed_versions} | jq -r '[ (.[].name | split("/"))[0] ] | join("|")')
                  helm list -A -a -f ${helm_list_filter}

                  # Describe how to fix the Helm releases
                  describe_how_to_fix_helm_releases="
                    \nBefore upgrading the cluster to Kubernetes ${next_k8s_version}, the Helm releases need to be fixed.

                    - For the Helm releases identified, you need to check for the latest version of the Chart (which has supported API versions)
                      or update the Chart yourself. Then deploy the updated Chart

                    - If the cluster was already upgraded to a new Kubernetes version without auditing for the removed API versions, it might be already running
                      with the removed API versions. When trying to redeploy the Helm Chart, you might encounter an error similar to the following:

                          Error: UPGRADE FAILED: current release manifest contains removed kubernetes api(s)
                          for this kubernetes version and it is therefore unable to build the kubernetes
                          objects for performing the diff.
                          Error from Kubernetes: unable to recognize \"\": no matches for kind "Deployment" in version "apps/v1beta1"

                      Helm fails in this scenario because it attempts to create a diff patch between the current deployed release
                      (which contains the Kubernetes APIs that are removed) against the Chart you are passing with the updated/supported API versions.

                      To fix this, you need to edit the release manifests that are stored in the cluster to use the supported API versions.
                      You can use the Helm 'mapkubeapis' plugin to update/patch the Helm releases to supported APIs.
                      Execute the following commands to patch the releases identified above:

                          helm plugin install https://github.com/helm/helm-mapkubeapis
                          helm mapkubeapis <NAME> -n <NAMESPACE>

                    NOTE: The best practice is to upgrade Helm releases that are using deprecated API versions to supported API versions
                          prior to upgrading to a Kubernetes version that removes those APIs.

                    For more information, refer to:
                      - https://helm.sh/docs/topics/kubernetes_apis
                      - https://github.com/helm/helm-mapkubeapis
                  "
                  echo -e "${describe_how_to_fix_helm_releases}"
                fi

                echo -e "${color_cyan}\nPress Enter to continue ...${color_reset}"
                read -r

                # Check EKS add-ons versions
                echo -e "\nChecking EKS add-ons versions..."
                addons=$(atmos describe component {{ .Arguments.component }} -s {{ .Flags.stack }} --format json | jq -r '.vars.addons')
                addons_count=$(echo ${addons} | jq -r '. | keys | length')
                if [[ "$addons_count" = 0 ]]; then
                  echo -e "${color_yellow}
                      \rCould not detect the 'addons' variable for the component '{{ .Arguments.component }}' in the stack '{{ .Flags.stack }}'.
                      \rMake sure that EKS add-ons are configured and provisioned on the EKS cluster.
                      \rRefer to https://docs.aws.amazon.com/eks/latest/userguide/eks-add-ons.html for more details.
                      ${color_reset}"
                else
                  echo -e "\nThere are currently ${addons_count} add-on(s) configured for the EKS component ${color_cyan}{{ .Arguments.component }}${color_reset} in the stack ${color_cyan}{{ .Flags.stack }}${color_reset} in the variable ${color_cyan}addons${color_reset}:\n"
                  echo ${addons} | yq --prettyPrint '.'
                  echo -e "\nKubernetes ${next_k8s_version} requires the following versions of the EKS add-ons:\n"

                  # Detect the latest supported versions of the EKS add-ons
                  addons_template=$(atmos describe component {{ .Arguments.component }} -s {{ .Flags.stack }} --format json | jq -r '.vars.addons')
                  for ((i=0; i<${addons_count}; i++)); do
                    addon_name=$(echo ${addons} | jq -r '(keys)['$i']')
                    addon_version=$(aws eks describe-addon-versions --kubernetes-version ${next_k8s_version} --addon-name ${addon_name} --query 'addons[].addonVersions[?compatibilities[0].defaultVersion].addonVersion' --output text)
                    addons_template=$(jq --arg addon_name "${addon_name}" --arg addon_version "${addon_version}" '.[$addon_name].addon_version = $addon_version' <<< "${addons_template}")
                  done

                  # Print the add-ons configuration for the desired Kubernetes version
                  echo ${addons_template} | yq --prettyPrint '.'
                fi

                # Describe how to provision the EKS component with the new Kubernetes version
                echo -e "${color_cyan}\nPress Enter to continue ...${color_reset}"
                read -r
                echo -e "\nAfter the Pods, Helm releases and EKS add-ons are configured and ready, do the following:\n
                  - Set the variable ${color_cyan}kubernetes_version${color_reset} to ${color_cyan}${next_k8s_version}${color_reset} for the EKS component ${color_cyan}{{ .Arguments.component }}${color_reset} in the stack ${color_cyan}{{ .Flags.stack }}${color_reset}
                  - Run the command ${color_cyan}atmos terraform apply {{ .Arguments.component }} -s {{ .Flags.stack }}${color_reset} to provision the component
                  - Run the command ${color_cyan}kubectl get pods -A${color_reset} to check the status of all Pods after the upgrade
                  - Run the command ${color_cyan}helm list -A -a${color_reset} to check the status of all Helm releases after the upgrade
                "

# Integrations
integrations:
  # Atlantis integration
  # https://www.runatlantis.io/docs/repo-level-atlantis-yaml.html
  atlantis:
    # Path and name of the Atlantis config file 'atlantis.yaml'
    # Supports absolute and relative paths
    # All the intermediate folders will be created automatically (e.g. 'path: /config/atlantis/atlantis.yaml')
    # Can be overridden on the command line by using '--output-path' command-line argument in 'atmos atlantis generate repo-config' command
    # If not specified (set to an empty string/omitted here, and set to an empty string on the command line), the content of the file will be dumped to 'stdout'
    # On Linux/macOS, you can also use '--output-path=/dev/stdout' to dump the content to 'stdout' without setting it to an empty string in 'atlantis.path'
    path: "atlantis.yaml"

    # Config templates
    # Select a template by using the '--config-template <config_template>' command-line argument in 'atmos atlantis generate repo-config' command
    config_templates:
      config-1:
        version: 3
        automerge: true
        delete_source_branch_on_merge: true
        parallel_plan: true
        parallel_apply: true
        allowed_regexp_prefixes:
          - dev/
          - staging/
          - prod/

    # Project templates
    # Select a template by using the '--project-template <project_template>' command-line argument in 'atmos atlantis generate repo-config' command
    project_templates:
      project-1:
        # generate a project entry for each component in every stack
        name: "{tenant}-{environment}-{stage}-{component}"
        workspace: "{workspace}"
        dir: "{component-path}"
        terraform_version: v1.2
        delete_source_branch_on_merge: true
        autoplan:
          enabled: true
          when_modified:
            - "**/*.tf"
            - "varfiles/$PROJECT_NAME.tfvars.json"
        apply_requirements:
          - "approved"

    # Workflow templates
    # https://www.runatlantis.io/docs/custom-workflows.html#custom-init-plan-apply-commands
    # https://www.runatlantis.io/docs/custom-workflows.html#custom-run-command
    workflow_templates:
      workflow-1:
        plan:
          steps:
            - run: terraform init -input=false
            # When using workspaces, you need to select the workspace using the $WORKSPACE environment variable
            - run: terraform workspace select $WORKSPACE || terraform workspace new $WORKSPACE
            # You must output the plan using '-out $PLANFILE' because Atlantis expects plans to be in a specific location
            - run: terraform plan -input=false -refresh -out $PLANFILE -var-file varfiles/$PROJECT_NAME.tfvars.json
        apply:
          steps:
            - run: terraform apply $PLANFILE

  # Atmos Pro integration
  pro:
    host: atmos-pro.com
    timeout: 3
    events:
      pull_request:
        - on: [open, synchronize, reopen]
          workflow: atmos-plan.yml
          dispatch_only_top_level_stacks: true
        - on: [merge]
          workflow: atmos-apply.yaml
      release:
        - on: [publish]
          workflow: atmos-apply.yaml

# Validation schemas (for validating atmos stacks and components)
schemas:
  # https://json-schema.org
  jsonschema:
    # Can also be set using 'ATMOS_SCHEMAS_JSONSCHEMA_BASE_PATH' ENV var, or '--schemas-jsonschema-dir' command-line argument
    # Supports both absolute and relative paths
    base_path: "stacks/schemas/jsonschema"
  # https://www.openpolicyagent.org
  opa:
    # Can also be set using 'ATMOS_SCHEMAS_OPA_BASE_PATH' ENV var, or '--schemas-opa-dir' command-line argument
    # Supports both absolute and relative paths
    base_path: "stacks/schemas/opa"
  # JSON Schema to validate Atmos manifests
  # https://atmos.tools/cli/schemas/
  # https://atmos.tools/cli/commands/validate/stacks/
  # https://atmos.tools/quick-start/advanced/configure-validation/
  # https://atmos.tools/schemas/atmos/atmos-manifest/1.0/atmos-manifest.json
  # https://json-schema.org/draft/2020-12/release-notes
  # https://www.schemastore.org/json
  # https://github.com/SchemaStore/schemastore
  atmos:
    # Can also be set using 'ATMOS_SCHEMAS_ATMOS_MANIFEST' ENV var, or '--schemas-atmos-manifest' command-line argument
    # Supports both absolute and relative paths (relative to the `base_path` setting in `atmos.yaml`)
    manifest: "stacks/schemas/atmos/atmos-manifest/1.0/atmos-manifest.json"

# CLI command aliases
aliases:
  # Aliases for Atmos native commands
  tf: terraform
  tp: terraform plan
  up: terraform apply
  down: terraform destroy
  ds: describe stacks
  dc: describe component
  # Aliases for Atmos custom commands
  ls: list stacks
  lc: list components

# `Go` templates in Atmos manifests
# https://atmos.tools/core-concepts/stacks/templates
# https://pkg.go.dev/text/template
templates:
  settings:
    enabled: true
    # https://masterminds.github.io/sprig
    sprig:
      enabled: true
    # https://docs.gomplate.ca
    gomplate:
      enabled: true
      timeout: 5
      # https://docs.gomplate.ca/datasources
      datasources: {}

settings:
  # `list_merge_strategy` specifies how lists are merged in Atmos stack manifests.
  # Can also be set using 'ATMOS_SETTINGS_LIST_MERGE_STRATEGY' environment variable, or '--settings-list-merge-strategy' command-line argument
  # The following strategies are supported:
  # `replace`: Most recent list imported wins (the default behavior).
  # `append`:  The sequence of lists is appended in the same order as imports.
  # `merge`:   The items in the destination list are deep-merged with the items in the source list.
  #            The items in the source list take precedence.
  #            The items are processed starting from the first up to the length of the source list (the remaining items are not processed).
  #            If the source and destination lists have the same length, all items in the destination lists are
  #            deep-merged with all items in the source list.
  list_merge_strategy: replace

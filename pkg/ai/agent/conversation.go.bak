package agent

import (
	"context"
	"fmt"
	"strings"

	"github.com/anthropics/anthropic-sdk-go"

	"github.com/cloudposse/atmos/pkg/schema"
)

// Conversation manages a conversation context with the AI.
type Conversation struct {
	client    *Client
	tools     *AtmosTools
	messages  []anthropic.MessageParam
	systemPrompt string
}

// NewConversation creates a new conversation with the AI.
func NewConversation(client *Client, atmosConfig *schema.AtmosConfiguration) *Conversation {
	tools := NewAtmosTools(atmosConfig)
	systemPrompt := generateSystemPrompt(atmosConfig)

	return &Conversation{
		client:       client,
		tools:        tools,
		messages:     make([]anthropic.MessageParam, 0),
		systemPrompt: systemPrompt,
	}
}

// generateSystemPrompt creates a system prompt that provides context about Atmos.
func generateSystemPrompt(atmosConfig *schema.AtmosConfiguration) string {
	prompt := `You are an AI assistant specialized in helping with Atmos, a sophisticated CLI tool for managing complex cloud infrastructure using Terraform.

# About Atmos
Atmos provides:
- Stack-based configuration management with hierarchical YAML configs
- Multi-cloud orchestration for Terraform, Helmfile, and Packer
- Component architecture for reusable infrastructure patterns
- Advanced templating with Go templates and Gomplate functions
- Workflow orchestration for complex deployment pipelines
- Policy validation using OPA and JSON Schema
- Vendoring system for external components
- Terminal UI with rich interactive components

# Your Role
You are an expert Atmos consultant who can:
- Help users understand Atmos concepts and architecture
- Analyze component and stack configurations
- Suggest best practices for infrastructure management
- Debug configuration issues
- Guide users through complex workflows
- Explain Terraform integration patterns
- Recommend optimization strategies

# Available Tools
You have access to several Atmos-specific tools that let you:
- Describe components and their configurations
- List available components and stacks
- Validate stack configurations
- Generate Terraform plans (read-only)
- Access Atmos settings and configuration

# Guidelines
- Always ask clarifying questions if the user's request is ambiguous
- Use the available tools to provide accurate, current information
- Explain Atmos concepts clearly with examples when helpful
- Be proactive in suggesting related improvements or optimizations
- Focus on practical, actionable advice
- When showing configuration examples, use proper YAML formatting
- Always validate configurations before suggesting changes`

	// Add current configuration context if available
	if atmosConfig != nil {
		prompt += fmt.Sprintf("\n\n# Current Atmos Configuration Context\n")
		if atmosConfig.Components.Terraform.BasePath != "" {
			prompt += fmt.Sprintf("- Terraform components path: %s\n", atmosConfig.Components.Terraform.BasePath)
		}
		if atmosConfig.Stacks.BasePath != "" {
			prompt += fmt.Sprintf("- Stacks configuration path: %s\n", atmosConfig.Stacks.BasePath)
		}
	}

	return prompt
}

// AddUserMessage adds a user message to the conversation.
func (c *Conversation) AddUserMessage(content string) {
	message := anthropic.NewUserMessage(anthropic.NewTextBlock(content))
	c.messages = append(c.messages, message)
}

// AddAssistantMessage adds an assistant message to the conversation.
func (c *Conversation) AddAssistantMessage(content string) {
	message := anthropic.NewAssistantMessage(anthropic.NewTextBlock(content))
	c.messages = append(c.messages, message)
}

// SendMessage sends a message and returns the AI response.
func (c *Conversation) SendMessage(ctx context.Context, userMessage string) (string, error) {
	// Add user message to conversation
	c.AddUserMessage(userMessage)

	// Prepare message parameters
	params := anthropic.MessageNewParams{
		Model:     anthropic.Model(c.client.GetModel()),
		MaxTokens: anthropic.Int(int64(c.client.GetConfig().MaxTokens)),
		Messages:  c.messages,
		System:    []anthropic.TextBlockParam{anthropic.NewTextBlock(c.systemPrompt)},
		Tools:     c.tools.GetAvailableTools(),
	}

	// Send message
	response, err := c.client.CreateMessage(ctx, params)
	if err != nil {
		return "", fmt.Errorf("failed to send message: %w", err)
	}

	// Process response and handle tool calls
	return c.processResponse(ctx, response)
}

// SendMessageStream sends a message and returns a streaming response.
func (c *Conversation) SendMessageStream(ctx context.Context, userMessage string) (*anthropic.MessagesStreamEventHandler[anthropic.Message], error) {
	// Add user message to conversation
	c.AddUserMessage(userMessage)

	// Prepare message parameters
	params := anthropic.MessageNewParams{
		Model:     anthropic.Model(c.client.GetModel()),
		MaxTokens: anthropic.Int(int64(c.client.GetConfig().MaxTokens)),
		Messages:  c.messages,
		System:    []anthropic.TextBlockParam{anthropic.NewTextBlock(c.systemPrompt)},
		Tools:     c.tools.GetAvailableTools(),
	}

	// Create streaming message
	return c.client.CreateMessageStream(ctx, params)
}

// processResponse processes the AI response and handles tool calls.
func (c *Conversation) processResponse(ctx context.Context, response *anthropic.Message) (string, error) {
	var responseText strings.Builder
	var toolResults []anthropic.MessageParam

	// Process each content block
	for _, content := range response.Content {
		switch contentBlock := content.AsUnion().(type) {
		case anthropic.TextBlock:
			responseText.WriteString(contentBlock.Text)
		case anthropic.ToolUseBlock:
			// Execute the tool
			result, err := c.tools.ExecuteTool(ctx, contentBlock)
			if err != nil {
				result = fmt.Sprintf("Error executing tool %s: %s", contentBlock.Name, err.Error())
			}

			// Add tool result to conversation
			toolResults = append(toolResults, anthropic.NewUserMessage(
				anthropic.NewToolResultBlock(contentBlock.ID, result, false),
			))
		}
	}

	// If there were tool calls, we need to send the results back and get the final response
	if len(toolResults) > 0 {
		// Add assistant message with tool calls
		c.messages = append(c.messages, anthropic.MessageParam{
			Role:    anthropic.MessageRoleAssistant,
			Content: response.Content,
		})

		// Add tool results
		c.messages = append(c.messages, toolResults...)

		// Get final response
		finalParams := anthropic.MessageNewParams{
			Model:     anthropic.Model(c.client.GetModel()),
			MaxTokens: anthropic.Int(int64(c.client.GetConfig().MaxTokens)),
			Messages:  c.messages,
			System:    []anthropic.TextBlockParam{anthropic.NewTextBlock(c.systemPrompt)},
			Tools:     c.tools.GetAvailableTools(),
		}

		finalResponse, err := c.client.CreateMessage(ctx, finalParams)
		if err != nil {
			return "", fmt.Errorf("failed to get final response: %w", err)
		}

		// Extract text from final response
		for _, content := range finalResponse.Content {
			if textBlock, ok := content.AsUnion().(anthropic.TextBlock); ok {
				responseText.WriteString(textBlock.Text)
			}
		}

		// Add final response to conversation
		c.messages = append(c.messages, anthropic.MessageParam{
			Role:    anthropic.MessageRoleAssistant,
			Content: finalResponse.Content,
		})
	} else {
		// No tool calls, just add the response to conversation
		c.messages = append(c.messages, anthropic.MessageParam{
			Role:    anthropic.MessageRoleAssistant,
			Content: response.Content,
		})
	}

	return responseText.String(), nil
}

// GetMessages returns the current conversation messages.
func (c *Conversation) GetMessages() []anthropic.MessageParam {
	return c.messages
}

// ClearConversation clears the conversation history.
func (c *Conversation) ClearConversation() {
	c.messages = make([]anthropic.MessageParam, 0)
}
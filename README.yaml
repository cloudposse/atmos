name: atmos

license: APACHE2

github_repo: cloudposse/atmos

badges:
  - name: Latest Release
    image: https://img.shields.io/github/release/cloudposse/atmos.svg
    url: https://github.com/cloudposse/atmos/releases/latest
  - name: Slack Community
    image: https://slack.cloudposse.com/badge.svg
    url: https://slack.cloudposse.com

related:
  - name: variant2
    description: Turn your bash scripts into a modern, single-executable CLI app today
    url: https://github.com/mumoshu/variant2

categories:
  - cli
  - automation
  - cloud
  - devops
  - workflow
  - terraform
  - helm
  - helmfile
  - kubernetes
  - aws

description: Universal Tool for DevOps and Cloud Automation.

introduction: |-

  `atmos` is both a library and a command-line tool for provisioning, managing and orchestrating workflows across various toolchains.
  We use it extensively for automating cloud infrastructure and [Kubernetes](https://kubernetes.io/) clusters.

  `atmos` includes workflows for dealing with:

     - Provisioning [Terraform](https://www.terraform.io/) components
     - Deploying [helm](https://helm.sh/) [charts](https://helm.sh/docs/topics/charts/) to Kubernetes clusters using [helmfile](https://github.com/roboll/helmfile)
     - Executing [helm](https://helm.sh/) commands on Kubernetes clusters
     - Provisioning [istio](https://istio.io/) on Kubernetes clusters using [istio operator](https://istio.io/latest/blog/2019/introducing-istio-operator/) and helmfile
     - Executing [kubectl](https://kubernetes.io/docs/reference/kubectl/overview/) commands on Kubernetes clusters
     - Executing [AWS SDK](https://aws.amazon.com/tools/) commands to orchestrate cloud infrastructure
     - Running [AWS CDK](https://aws.amazon.com/cdk/) constructs to define cloud resources
     - Executing commands for the [serverless](https://www.serverless.com/) framework
     - Executing shell commands
     - Combining various commands into workflows to execute many commands sequentially in just one step
     - ... and many more

  In essence, it's a tool that orchestrates the other CLI tools in a consistent and self-explaining manner.
  It's a superset of all other tools and task runners (e.g. `make`, `terragrunt`, `terraform`, `aws` cli, `gcloud`, etc)
  and intended to be used to tie everything together, so you can provide a simple CLI interface for your organization.

  Moreover, `atmos` is not only a command-line interface for managing clouds and clusters. It provides many useful patterns and best practices, such as:

  - Enforces Terraform and helmfile project structure (so everybody knows where things are)
  - Provides separation of configuration and code (so the same code could be easily deployed to different regions, environments and stages)
  - It can be extended to include new features, commands, and workflows
  - The commands have a clean, consistent and easy to understand syntax
  - The CLI can be compiled into a binary and included in other tools and containers for DevOps, cloud automation and CI/CD
  - The CLI code is modular and self-documenting


  ## CLI Structure

  The CLI is built with [variant2](https://github.com/mumoshu/variant2) using [HCL syntax](https://www.terraform.io/docs/configuration/index.html).

  `*.variant` files are combined like Terraform files.

  See `variant` docs for more information on [writing commands](https://github.com/mumoshu/variant2#writing-commands).

  The CLI code consists of self-documenting [modules](atmos/modules) (separating the files into modules is done for cleanliness):

    - utils - a collection of utilities to use in other modules
    - shell - `shell` commands and helpers for the other modules
    - terraform - `terraform` commands (`plan`, `apply`, `deploy`, `destroy`, `import`, etc.)
    - helm - `helm` commands (e.g. `list`)
    - helmfile - `helmfile` commands (`diff`, `apply`, `deploy`, `destroy`, `sync`, `lint`, etc.)
    - kubeconfig - commands to download and manage `kubeconfig` from EKS clusters
    - istio - commands to manage `istio` using `istio-operator` and `helmfile`
    - workflow - commands to construct and execute cloud automation workflows


  ## Developing Your Own CLI

  One way to use this project is by writing your own custom CLI that leverages our atmos.

  This is ideal when you have your own workflows that you want to develop in addition to using the ones we've developed for you.

  For example, maybe you have your own existing CLI tools (e.g. using `terragrunt`). In this case, you may want to start by developing your own CLI.


  ## Usage

  There are a number of ways you can leverage this project:

    1. As a **standalone CLI** - you can use our CLI without any modification and get immediate gratification
    2. As a **library** - you can import our `variant` modules into your own CLI and expand the workflows for your needs
    3. As a **Docker image** - you can use our [Docker image](example/Dockerfile) the way you would the `cli` and run the workflows


  ## Recommended Layout

  Our recommended filesystem layout looks like this:

    ~~~
       │   # CLI configuration
       └── cli/
       │  
       │   # Centralized components configuration
       ├── stacks/
       │   │
       │   └── $stack.yaml
       │  
       │   # Components are broken down by tool
       ├── components/
       │   │
       │   ├── terraform/   # root modules in here
       │   │   ├── vpc/
       │   │   ├── eks/
       │   │   ├── rds/
       │   │   ├── iam/
       │   │   ├── dns/
       │   │   └── sso/
       │   │
       │   └── helmfile/  # helmfiles are organized by chart
       │       ├── cert-manager/helmfile.yaml
       │       └── external-dns/helmfile.yaml
       │  
       │   # Makefile for building the CLI
       ├── Makefile
       │  
       │   # Docker image for shipping the CLI and all dependencies
       └── Dockerfile (optional)

    ~~~


  ## Example

  The [example](example) folder contains a complete solution that shows how to:

    - Structure the Terraform and helmfile components
    - Configure the CLI top-level module [main.variant](example/cli/main.variant)
    - Add [stack configurations](example/stacks) for the Terraform and helmfile components (to provision them to different environments and stages)
    - Create a [Dockerfile](example/Dockerfile) with commands to build and include the CLI into the container
    - Combine many CLI commands into workflows and run the workflows to provision resources

  In the example, we show how to create and provision (using the CLI) the following resources for three different environments/stages:

    - VPCs for `dev`, `staging` and `prod` stages in the `us-east-2` region (which we refer to as `ue2` environment)
    - EKS clusters in the `ue2` environment for `dev`, `staging` and `prod`
    - `nginx-ingress` helmfile to be deployed on all EKS clusters


  ## CLI Configuration

    The CLI top-level module [main.variant](example/cli/main.variant) contains the global settings (options) for the CLI, including the location of the Terraform components,
    helmfiles, and stack configurations.

    It's configured for that particular example project, but can be changed to reflect the desired project structure.

  In the example we have the following:

    - The terraform components are in the `components/terraform` folder - we set that global option in [main.variant](example/cli/main.variant)
    ```hcl
      option "terraform-dir" {
        default     = "./components/terraform"
        description = "Terraform components directory"
        type        = string
      }
    ```

    - The helmfiles are in the `components/helmfile` folder - we set that global option in [main.variant](example/cli/main.variant)
    ```hcl
      option "helmfile-dir" {
        default     = "./components/helmfile"
        description = "Helmfile components directory"
        type        = string
      }
    ```

    - The stack configurations (Terraform and helmfile variables) are in the [stacks](example/stacks) folder - we set that global option in [main.variant](example/cli/main.variant)
    ```hcl
      option "config-dir" {
        default     = "./stacks"
        description = "Stacks config directory"
        type        = string
      }
    ```

  [main.variant](example/cli/main.variant) also includes the `imports` statement that imports all the required modules from the `atmos` repo.

  __NOTE:__ For the example, we import all the CLI modules, but they could be included selectively depending on a particular usage.

    ```hcl
        imports = [
          "git::https://git@github.com/cloudposse/atmos@modules/utils?ref=master",
          "git::https://git@github.com/cloudposse/atmos@modules/shell?ref=master",
          "git::https://git@github.com/cloudposse/atmos@modules/kubeconfig?ref=master",
          "git::https://git@github.com/cloudposse/atmos@modules/terraform?ref=master",
          "git::https://git@github.com/cloudposse/atmos@modules/helmfile?ref=master",
          "git::https://git@github.com/cloudposse/atmos@modules/helm?ref=master",
          "git::https://git@github.com/cloudposse/atmos@modules/workflow?ref=master",
          "git::https://git@github.com/cloudposse/atmos@modules/istio?ref=master",
          "git::https://git@github.com/cloudposse/atmos@modules/vendir?ref=master"
      ]
    ```

  __NOTE:__ `imports` statement supports `https`, `http`, and `ssh` protocols.

  __NOTE:__ The global options from [main.variant](example/cli/main.variant) are propagated to all the downloaded modules,
  so they need to be specified only in one place - in the top-level module.

  When we build the Docker image, all the modules from the `imports` statement are downloaded, combined with the top-level module [main.variant](example/cli/main.variant),
  and compiled into a binary, which then included in the Docker container.


  ## Centralized Project Configuration

  `atmos` provides separation of configuration and code, allowing you to provision the same code into different regions, environments and stages.

  In our example, all the code (Terraform and helmfiles) is in the [components](example/components) folder.

  The centralized stack configurations (variables for the Terraform and helmfile components) are in the [stacks](example/stacks) folder.

  In the example, all stack configuration files are broken down by environments and stages and use the predefined format `$environment-$stage.yaml`.

  Environments are abbreviations of AWS regions, e.g. `ue2` stands for `us-east-2`, whereas `uw2` would stand for `us-west-2`.

  `$environment-globals.yaml` is where you define the global values for all stages for a particular environment.
  The global values get merged with the `$environment-$stage.yaml` configuration for a specific environment/stage by the CLI.

  In the example, we defined a few config files:

    - [ue2-dev.yaml](example/stacks/ue2-dev.yaml) - stack configuration (Terraform and helmfile variables) for the environment `ue2` and stage `dev`
    - [ue2-staging.yaml](example/stacks/ue2-staging.yaml) - stack configuration (Terraform and helmfile variables) for the environment `ue2` and stage `staging`
    - [ue2-prod.yaml](example/stacks/ue2-prod.yaml) - stack configuration (Terraform and helmfile variables) for the environment `ue2` and stage `prod`
    - [ue2-globals.yaml](example/stacks/ue2-globals.yaml) - global settings for the environment `ue2` (e.g. `region`, `environment`)
    - [globals.yaml](example/stacks/globals.yaml) - global settings for the entire solution

  __NOTE:__ The stack configuration structure and the file names described above are just an example of how to name and structure the config files.
  You can choose any file name for a stack. You can also include other configuration files (e.g. globals for the environment, and globals for the entire solution)
  into a stack config using the `import` directive.

  __NOTE:__ Currently `atmos` supports 10 levels of imports, e.g. you can import another config into a stack config, which in turn can import yet another config, etc.
  See [stacks](example/stacks) for more details.

  Stack configuration files have a predefined format:

    ```yaml
      import:
        - ue2-globals

      vars:
        stage: dev

      terraform:
        vars:

      helmfile:
        vars:

      components:
        terraform:
          vpc:
            command: "/usr/bin/terraform-0.13"
            backend:
              s3:
                workspace_key_prefix: "vpc"
            vars:
              cidr_block: "10.102.0.0/18"
          eks:
            backend:
              s3:
                workspace_key_prefix: "eks"
            vars:

        helmfile:
          nginx-ingress:
            vars:
              installed: true

      workflows:
        deploy-all:
    ```

  It has the following main sections:

    - `import` - (optional) a list of stack configuration files to import and combine with the current configuration file
    - `vars` - (optional) a map of variables for all components (Terraform and helmfile) in the stack
    - `terraform` - (optional) configuration (variables) for all Terraform components
    - `helmfile` - (optional) configuration (variables) for all helmfile components
    - `components` - (required) configuration for the Terraform and helmfile components
    - `workflows` - (optional) workflow definitions for the stack (see [Workflows](#Workflows) section below for the more detailed description of workflows)

  The `components` section consists of the following:

     - `terraform` - defines variables, the binary to execute, and the backend for each Terraform component.
        Terraform component names correspond to the Terraform components in the [components](example/components) folder

     - `helmfile` - defines variables and the binary to execute for each helmfile component.
        Helmfile component names correspond to the helmfile components in the [helmfile](example/components/helmfile) folder


  ## Run the Example

  To run the example, execute the following commands in a terminal:

    - `cd example`
    - `make all` - it will build the Docker image, build the CLI tool inside the image, and then start the container

  Note that the name of the CLI executable is configurable.

  In the [Dockerfile](example/Dockerfile) for the example, we've chosen the name `atmos`, but it could be any name you want, for example
  `ops`, `cli`, `ops-exe`, etc. The name of the CLI executable is configured using `ARG CLI_NAME=atmos` in the Dockerfile.

  After the container starts, run `atmos help` to see the available commands and available flags.

  __NOTE:__ We use the Cloud Posse [geodesic](https://github.com/cloudposse/geodesic) image as the base image for the container.
  This is not strictly a requirement, but our base image ships with all the standard tools for cloud automation that we depend on (e.g. `terraform`, `helm`, `helmfile`, etc).


  ## Provision Terraform Component

  To provision a Terraform component using the `atmos` CLI, run the following commands in the container shell:

    ```bash
      atmos terraform plan eks --stack=ue2-dev
      atmos terraform apply eks --stack=ue2-dev
    ```

  where:

    - `eks` is the Terraform component to provision (from the `components/terraform` folder)
    - `--stack=ue2-dev` is the stack to provision the component into

  Short versions of the command-line arguments can be used:

    ```bash
      atmos terraform plan eks -s ue2-dev
      atmos terraform apply eks -s ue2-dev
    ```

  To execute `plan` and `apply` in one step, use `terrafrom deploy` command:

    ```bash
      atmos terraform deploy eks -s ue2-dev
    ```

  ## Provision Helmfile Component

  To provision a helmfile component using the `atmos` CLI, run the following commands in the container shell:

    ```bash
      atmos helmfile diff nginx-ingress --stack=ue2-dev
      atmos helmfile apply nginx-ingress --stack=ue2-dev
    ```

  where:

    - `nginx-ingress` is the helmfile component to provision (from the `components/helmfile` folder)
    - `--stack=ue2-dev` is the stack to provision the component into

  Short versions of the command-line arguments can be used:

    ```bash
      atmos helmfile diff nginx-ingress -s ue2-dev
      atmos helmfile apply nginx-ingress -s ue2-dev
    ```

  To execute `diff` and `apply` in one step, use `helmfile deploy` command:

    ```bash
      atmos helmfile deploy nginx-ingress -s ue2-dev
    ```


  ## Workflows

  Workflows are a way of combining multiple commands into one executable unit of work.

  In the CLI, workflows can be defined using two different methods:

    - In the configuration file for a stack (see [workflows in ue2-dev.yaml](example/stacks/ue2-dev.yaml) for an example)
    - In a separate file (see [workflows.yaml](example/stacks/workflows.yaml)

  In the first case, we define workflows in the configuration file for the stack (which we specify on the command line).
  To execute the workflows from [workflows in ue2-dev.yaml](example/stacks/ue2-dev.yaml), run the following commands:

    ```bash
      atmos workflow deploy-all -s ue2-dev
    ```

  Note that workflows defined in the stack config files can be executed only for the particular stack (environment and stage).
  It's not possible to provision resources for multiple stacks this way.

  In the second case (defining workflows in a separate file), a single workflow can be created to provision resources into different stacks.
  The stacks for the workflow steps can be specified in the workflow config.

  For example, to run `terraform plan` and `helmfile diff` on all terraform and helmfile components in the example, execute the following command:

    ```bash
      atmos workflow plan-all -f workflows
    ```

  where the command-line option `-f` (`--file` for long version) instructs the `atmos` CLI to look for the `plan-all` workflow in the file [workflows](example/stacks/workflows.yaml).

  As we can see, in multi-environment workflows, each workflow job specifies the stack it's operating on:

    ```yaml
    workflows:
      plan-all:
        description: Run 'terraform plan' and 'helmfile diff' on all components for all stacks
        steps:
          - job: terraform plan vpc
            stack: ue2-dev
          - job: terraform plan eks
            stack: ue2-dev
          - job: helmfile diff nginx-ingress
            stack: ue2-dev
          - job: terraform plan vpc
            stack: ue2-staging
          - job: terraform plan eks
            stack: ue2-staging
    ```

  You can also define a workflow in a separate file without specifying the stack in the workflow's job config.
  In this case, the stack needs to be provided on the command line.

  For example, to run the `deploy-all` workflow from the [workflows](example/stacks/workflows.yaml) file for the `ue2-dev` stack,
  execute the following command:

    ```bash
      atmos workflow deploy-all -f workflows -s ue2-dev
    ```

contributors:
  - name: Erik Osterman
    github: osterman
  - name: Andriy Knysh
    github: aknysh
